{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    },
    "colab": {
      "name": "chw-3_Hannah_Shanes.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hshanes/hw4503/blob/main/chw_3_Hannah_Shanes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KvtCb8PYOm_"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scaomath/wustl-math450/blob/main/Homework/chw-3_YOUR_NAME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIiEePMuYOnU"
      },
      "source": [
        "# Homework 3: Classification problems\n",
        "Name: Hannah Shanes\n",
        "\n",
        "Wustlkey: hshanes\n",
        "\n",
        "Partner Name (if applicable):\n",
        "\n",
        "Partner Wustlkey (if applicable):\n",
        "\n",
        "### Submission instructions\n",
        "\n",
        "- Submit the modified python notebook as homework submission.\n",
        "- Group submission is enabled, you can submit this coding assignment with up to 1 teammate in our class. For instruction of how to do a group submission. Please refer to Canvas useful links.\n",
        "- You can google answers on StackOverflow, please attach the corresponding StackOverflow answer as comments. However, if the answer is converted to `torch` format, no credit will be awarded.\n",
        "- Do not change the number of cells! Please work in the cell provided. If we need extra cells for debugging and testing purposes, we can work at the end of this notebook, save everything as a backup for review, and delete the extra cells in the submitted version.\n",
        "\n",
        " \n",
        "\n",
        "### Instructions\n",
        "Do **not** use `for` loops for computational purpose in any of our solutions! We are allowed to use `for` loops to display figures etc.\n",
        "Efficieny will be graded as well. For example if a problem asks us generate an array from 0 to 9: then\n",
        "```python\n",
        "x = []\n",
        "for i in range(10):\n",
        "    x.append(i)\n",
        "```\n",
        "this will only result a partial credit while\n",
        "```python\n",
        "x = np.arange(10)\n",
        "```\n",
        "or\n",
        "```python\n",
        "x = torch.arange(10)\n",
        "```\n",
        "will yield a full score.\n",
        "\n",
        "### Problems\n",
        "Below are 4 problems that explore the needed data structure and operations for classification problems. Complete the coding tasks for credit.\n",
        "\n",
        "### Grading\n",
        "This homework has 4 problems, 5 points for each problem. The homework will be graded and the grade counts towards your course grade. \n",
        "\n",
        "## Coding environments and submission\n",
        "If we do not have `torch` installed on your computer, we have three ways to upload this notebook to [Google colab](https://colab.research.google.com/)：\n",
        "\n",
        "1. Open up Google Colab, choose `Upload` to upload this template and work there. After we have done working we can select `File->Download .ipynb`.\n",
        "2. Open up Google Colab, choose either `GitHub` or `Google Drive` to select the uploaded notebook in the corresponding website. After done working, we can sync the file to the corresponding GitHub or Google Drive copy.\n",
        "3. Use the \"Open in Colab\" button at the top."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc_-IlktYOnk"
      },
      "source": [
        "# Run Me First\n",
        "import torch\n",
        "\n",
        "# import torchvision \n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "# import packages that help us plot\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"dark\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-u2ciLEYOnl"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "\n",
        "\"MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\"\n",
        "\n",
        "In the following cells, we will learn how to load and view this dataset for our toy models. \n",
        "\n",
        "Read more:[https://www.kaggle.com/c/digit-recognizer](https://www.kaggle.com/c/digit-recognizer)\n",
        "\n",
        "\n",
        "<a title=\"By Josef Steppan [CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0)], from Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:MnistExamples.png\"><img width=\"512\" alt=\"MnistExamples\" src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\"/></a>\n",
        "\n",
        "\n",
        "---- \n",
        "This code is adopted from the pytorch examples repository. \n",
        "It is licensed under BSD 3-Clause \"New\" or \"Revised\" License.\n",
        "Source: https://github.com/pytorch/examples/\n",
        "LICENSE: https://github.com/pytorch/examples/blob/master/LICENSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmZbs_YMYOnp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0ae5c5-82c4-40f2-d488-85c660db5a76"
      },
      "source": [
        "\n",
        "## update as of Mar 11\n",
        "!wget https://sites.wustl.edu/scao/files/2021/03/MNIST.tar_.gz\n",
        "!mv MNIST.tar_.gz MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-14 19:36:38--  https://sites.wustl.edu/scao/files/2021/03/MNIST.tar_.gz\n",
            "Resolving sites.wustl.edu (sites.wustl.edu)... 34.215.37.29, 34.216.237.15\n",
            "Connecting to sites.wustl.edu (sites.wustl.edu)|34.215.37.29|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cpb-us-w2.wpmucdn.com/sites.wustl.edu/dist/1/2774/files/2021/03/MNIST.tar_.gz [following]\n",
            "--2021-03-14 19:36:39--  https://cpb-us-w2.wpmucdn.com/sites.wustl.edu/dist/1/2774/files/2021/03/MNIST.tar_.gz\n",
            "Resolving cpb-us-w2.wpmucdn.com (cpb-us-w2.wpmucdn.com)... 151.139.244.23\n",
            "Connecting to cpb-us-w2.wpmucdn.com (cpb-us-w2.wpmucdn.com)|151.139.244.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23197619 (22M) [application/gzip]\n",
            "Saving to: ‘MNIST.tar_.gz’\n",
            "\n",
            "MNIST.tar_.gz       100%[===================>]  22.12M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2021-03-14 19:36:39 (235 MB/s) - ‘MNIST.tar_.gz’ saved [23197619/23197619]\n",
            "\n",
            "./MNIST/\n",
            "./MNIST/processed/\n",
            "./MNIST/raw/\n",
            "./MNIST/raw/train-images-idx3-ubyte\n",
            "./MNIST/raw/train-labels-idx1-ubyte\n",
            "./MNIST/raw/train-images-idx3-ubyte.gz\n",
            "./MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "./MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "./MNIST/raw/t10k-labels-idx1-ubyte\n",
            "./MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "./MNIST/raw/t10k-images-idx3-ubyte\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqDN4kK9YOnp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7940912-6555-4fd6-f474-abda166d606e"
      },
      "source": [
        "# download the data\n",
        "train = datasets.MNIST(root='./', train=True, download=True, transform = transforms.ToTensor())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./MNIST/raw/train-images-idx3-ubyte.gz\n",
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "Using downloaded and verified file: ./MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "Using downloaded and verified file: ./MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "Using downloaded and verified file: ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsovPAnqYOnq"
      },
      "source": [
        "data_new = train.data[:10000].clone() # first 10000 samples\n",
        "target_new = train.targets[:10000].clone()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzilPdqjYOnq"
      },
      "source": [
        "## One-hot encoding of labels\n",
        "\n",
        "Encode labels as a \"one-hot\" numeric array. In binary classification, essentially a vector representation of the following indicator function:\n",
        "$$\n",
        "1_{\\{y = k\\}} = \\delta_{yk} = \\begin{cases}\n",
        "1 & \\text{when } y = k,\n",
        "\\\\[5pt]\n",
        "0 & \\text{otherwise}.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "For example, if we have 4 classes `0, 1, 2, 3`, class `0` will be one-hot encoded as `[1, 0, 0, 0]`, and class `2` as `[0, 0, 1, 0]`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpLqVm7PYOnq"
      },
      "source": [
        "\n",
        "## Problem 1\n",
        "Write a function `one_hot_encode()` to convert the class labels of MNIST dataset to a matrix of one-hot encoded vectors,\n",
        "each row represents the label of a sample. You can use `for` loop, but `for` loop will not be rewarded with full credits.\n",
        "An example for `for` loop implementation is as follows\n",
        " \n",
        "```python\n",
        "n_sample = len(data_new)\n",
        "n_class = 10\n",
        "one_hot_encoded_labels = torch.zeros((n_sample, 10), dtype=torch.float)\n",
        "for i in range(n_sample):\n",
        "    k = target_new[i]\n",
        "    one_hot_encoded_labels[i, k] = 1\n",
        "```\n",
        "\n",
        "There are various way of implementation the one-hot encoding without `for` loop, for example, expanding dimensions, using an identity matrix, etc. You can google StackOverflow to get answers, please attach the corresponding StackOverflow answer as comments if you have done so. However, if the answer has not been converted to `torch` format, no credit will be awarded. Only the usage of a `torch` function is allowed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU3FEQXJYOnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a050412e-e34f-483f-8bea-69e5bc324b67"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def one_hot_encode(y):\n",
        "\n",
        "    classes=10\n",
        "    targets = np.array(y).reshape(-1)\n",
        "    return np.eye(classes)[targets]\n",
        "\n",
        "\n",
        "\n",
        "print(one_hot_encode(target_new[:10]))\n",
        "# expected output\n",
        "# tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
        "#         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "#         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
        "#         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "#         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
        "#         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
        "#         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "#         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
        "#         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "#         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1pDn09YYOnr"
      },
      "source": [
        "## Softmax function\n",
        "\n",
        "Softmax function is a tool for multi-class classification problem. Suppose that we know for a certain sample, its label $y\\in \\{1,\\dots, K\\}$ where $K$ is the number of all possible classes in the samples. For a sample image flattened $\\mathbf{x}\\in \\mathbb{R}^n$ (in MNIST it is a 28x28 image flattened to a `(784,)` array), we can estimate the probability that $P(y=k|\\mathbf{x})$ using our neural network's output as follows:\n",
        "\n",
        "$$\n",
        "\\begin{pmatrix}\n",
        "P(y = 1 | \\mathbf{x}; W) \\\\\n",
        "P(y = 2 | \\mathbf{x}; W) \\\\\n",
        "\\vdots \\\\\n",
        "P(y = K | \\mathbf{x}; W)\n",
        "\\end{pmatrix}\n",
        "=\\text{Softmax} (\\hat{y}_1, \\hat{y}_2, \\dots, \\hat{y}_K)\n",
        ":= \\frac{1}{ \\sum_{j=1}^{K}{\\exp\\big(\\hat{y}_j\\big) }}\n",
        "\\begin{pmatrix}\n",
        "\\exp(\\hat{y}_1) \\\\\n",
        "\\exp(\\hat{y}_2) \\\\\n",
        "\\vdots \\\\\n",
        "\\exp(\\hat{y}_K) \\\\\n",
        "\\end{pmatrix}.\n",
        "$$\n",
        "where we have $K$ outputs from a neutral network (preferably after a ReLU activation in the last layer), $\\hat{y}_1, \\hat{y}_2, \\dots, \\hat{y}_K$ are outputs,  and the factor $\\sum_{j=1}^{K}{\\exp\\big(\\hat{y}_j\\big)}$ normalizes the results to be a probability (each entry is between 0 to 1, and summing up to 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un5uzQ4-YOnr"
      },
      "source": [
        "## Problem 2\n",
        "\n",
        "Implement a vectorized `softmax()` function by ourselves without referring to `torch.nn.functional.softmax()`, i.e., for a `(N, 10)` matrix which contains the outputs of neural network, the function should return the same matrix with the `proba` produced in the following `for` loop:\n",
        "\n",
        "```python\n",
        "N = len(data_new)\n",
        "y_hat = torch.randn((N, 10)) # generate a random guess\n",
        "proba = torch.zeros_like(y_hat)\n",
        "for i in range(N):\n",
        "    exp_y_hat = torch.exp(y_hat[i])\n",
        "    sum_exp = torch.sum(exp_y_hat)\n",
        "    proba[i] = exp_y_hat/sum_exp\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhMCf5wBYOns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de657676-ab63-4fed-c965-8a3dd6cc8c76"
      },
      "source": [
        "def softmax(y):\n",
        "    '''\n",
        "    Replace this with your code\n",
        "    \n",
        "    Input:\n",
        "        - yhat: (N, K) matrix\n",
        "            N: number of samples\n",
        "            K: number of classes\n",
        "    Output:\n",
        "        - proba: (N, K) matrix\n",
        "    '''\n",
        "    y=torch.exp(y)\n",
        "    denom=y.sum(dim=1)\n",
        "    denom=denom.view(-1,1)\n",
        "    proba=y/denom\n",
        "    return proba\n",
        "\n",
        "\n",
        "N = len(data_new)\n",
        "y_hat = torch.randn((N, 10))\n",
        "proba = softmax(y_hat)\n",
        "print(torch.allclose(proba.sum(axis=1), torch.ones(N))) # expected output is True"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORQc5t__YOnt"
      },
      "source": [
        "## Generating the prediction \n",
        "\n",
        "After we get the probability, to predict which class this sample belongs to, we simply choose the biggest entry as the class.\n",
        "For example, if we have a 4-class classification problem, the predicted probability for a sample can be \n",
        "- `[0.3, 0.1, 0.4, 0.2]`,  the `pred` for this sample is of class `2`.\n",
        "- `[0.05, 0.8, 0.05, 0.1]`,  the `pred` for this sample is of class `1`.\n",
        "- `[0.6, 0.1, 0.2, 0.1]`,  the `pred` for this sample is of class `0`.\n",
        "\n",
        "## Metrics for classification problem\n",
        "\n",
        "- Accuracy: the simplest metric in classification, if the label(s) predicted for a sample match the true label(s) associated with this sample, we say this is a correct prediction, otherwise incorrect. The accuracy metric is simply:\n",
        "$$\n",
        "\\text{Acc} = \\frac{1}{N}\\sum_{i=1}^{N}\\frac{|y^{(i)}\\cap \\hat{y}(x^{(i)}; W)|}{| \\hat{y}(x^{(i)}; W)|} = \\frac{\\# \\text{Correct}}{\\# \\text{Total}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efsosnpgYOnt"
      },
      "source": [
        "## Problem 3\n",
        "\n",
        "Write a vectorized function `proba_to_pred()` that converts the predicted probability matrix in problem 2 to prediction vector, i.e., for each row of the probability matrix, find where its maximum entry is (the index of the maximum entry in that row).\n",
        "\n",
        "## Problem 4\n",
        "Write a vectorized function `accuracy_score()` function to compute the accuracy between predicted labels and the true labels. \n",
        "A `for` loop implementation can be follows: suppose `pred` is the predicted class vector that has same shape with `target_new` we defined earlier.\n",
        "\n",
        "```python\n",
        "N = len(target_new)\n",
        "counter = 0\n",
        "for i in range(N):\n",
        "    counter += (target_new[i] == pred[i])\n",
        "\n",
        "acc = counter/N\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze9_t9qsYOnu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f36faba-340d-41b2-a0dd-52a1c48212e4"
      },
      "source": [
        "def proba_to_pred(proba):\n",
        "    '''\n",
        "    Replace this with your code\n",
        "    \n",
        "    Input:\n",
        "        - predicted probability matrix: (N, K)\n",
        "            N: # samples\n",
        "            K: # of classes\n",
        "        \n",
        "    Output:\n",
        "        - pred: predicted classes (N, )\n",
        "    '''\n",
        "    pred = torch.argmax(proba, dim=1)\n",
        "\n",
        "    return pred\n",
        "\n",
        "def accuracy_score(y1, y2):\n",
        "    '''\n",
        "    Replace this with your code\n",
        "    \n",
        "    Input:\n",
        "        - predicted labels: one-hot encoded prediction\n",
        "        - true labels: one-hot encoded true labels\n",
        "\n",
        "    Output:\n",
        "        - accuracy score above\n",
        "    '''\n",
        "    acc=(y1==y2).float().mean()\n",
        "    \n",
        "    return acc\n",
        "\n",
        "\n",
        "y_hat = torch.randn((target_new.size(0), 10)).softmax(dim=1) # random guess then softmax\n",
        "pred = proba_to_pred(y_hat) # your implemented function in problem 3\n",
        "acc = accuracy_score(pred, target_new) \n",
        "\n",
        "print(pred.min(), pred.max()) # expected output: 0 9\n",
        "print(acc) # expected output approximately 0.1 (random guess's correct rate)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0) tensor(9)\n",
            "tensor(0.1037)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHcCIl73YOnv"
      },
      "source": [
        "# extra cells\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op3MPivGYOnw"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}